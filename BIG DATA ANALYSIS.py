# -*- coding: utf-8 -*-
"""task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M4TOn7ZIvE-g3s79r5ugWCf4EdBGClKG
"""

# Install PySpark (skip if already installed)
!pip install pyspark

# Import PySpark
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg, max, min
import pandas as pd
import random

# Step 1: Create Spark Session
spark = SparkSession.builder.appName("BigData_Analysis_Internship").getOrCreate()

# Step 2: Generate or Load Large Dataset
data = {'ID': range(1, 101),
        'Gender': [random.choice(['Male', 'Female']) for _ in range(100)],
        'Age': [random.randint(20, 60) for _ in range(100)],
        'Salary': [random.randint(30000, 120000) for _ in range(100)]}
dummy_df = pd.DataFrame(data)
dummy_df.to_csv("bigdata.csv", index=False)


df = spark.read.csv("bigdata.csv", header=True, inferSchema=True)

# Step 3: Show Dataset Info
print("=== Sample Data ===")
df.show(5)

print("=== Total Records ===")
print(df.count())

# Step 4: Perform Big Data Analysis
print("=== Average Salary by Gender ===")
avg_salary = df.groupBy("Gender").agg(avg("Salary").alias("Average_Salary"))
avg_salary.show()

print("=== Age Range ===")
df.select(min("Age").alias("Min_Age"), max("Age").alias("Max_Age")).show()

# Step 5: Example Filter Operation
print("=== High Earners (Salary > 1 Lakh) ===")
high_earners = df.filter(col("Salary") > 100000)
print("Count of high earners:", high_earners.count())

# Step 6: Save Output (optional)
avg_salary.write.mode("overwrite").csv("output_avg_salary")

# Stop Spark
spark.stop()
print("âœ… Big Data Analysis Completed Successfully!")